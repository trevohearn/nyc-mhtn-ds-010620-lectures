{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation for parameter tuning, model selection, and feature selection ([video #7](https://www.youtube.com/watch?v=6dbrR-WymjI&list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&index=7))\n",
    "\n",
    "Created by [Data School](http://www.dataschool.io/). Watch all 9 videos on [YouTube](https://www.youtube.com/playlist?list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A). Download the notebooks from [GitHub](https://github.com/justmarkham/scikit-learn-videos).\n",
    "\n",
    "**Note:** This notebook uses Python 3.6 and scikit-learn 0.19.1. The original notebook (shown in the video) used Python 2.7 and scikit-learn 0.16, and can be downloaded from the [archive branch](https://github.com/justmarkham/scikit-learn-videos/tree/archive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- What is the drawback of using the **train/test split** procedure for model evaluation?\n",
    "- How does **K-fold cross-validation** overcome this limitation?\n",
    "- How can cross-validation be used for selecting **tuning parameters**, choosing between **models**, and selecting **features**?\n",
    "- What are some possible **improvements** to cross-validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of model evaluation procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** Need a way to choose between machine learning models\n",
    "\n",
    "- Goal is to estimate likely performance of a model on **out-of-sample data**\n",
    "\n",
    "**Initial idea:** Train and test on the same data\n",
    "\n",
    "- But, maximizing **training accuracy** rewards overly complex models which **overfit** the training data\n",
    "\n",
    "**Alternative idea:** Train/test split\n",
    "\n",
    "- Split the dataset into two pieces, so that the model can be trained and tested on **different data**\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance\n",
    "- But, it provides a **high variance** estimate since changing which observations happen to be in the testing set can significantly change testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# implementation \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = sns.load_dataset('mpg')\n",
    "\n",
    "y = data[[\"mpg\"]]\n",
    "X = data.drop([\"mpg\", \"name\", \"origin\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use train/test split with different random_state values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cylinders\n",
       "3     99.250000\n",
       "4     78.441558\n",
       "5     85.000000\n",
       "6    102.301587\n",
       "8    157.819444\n",
       "Name: horsepower, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean horsepower for different levels of cylinders on the training data\n",
    "X_train.groupby('cylinders')['horsepower'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 99.2, 4: 78.4, 5: 85.0, 6: 102.3, 8: 157.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "#use those means to impute any missing values\n",
    "cyl_hp = X_train.groupby('cylinders')['horsepower'].mean().round(1).to_dict()\n",
    "print(cyl_hp)\n",
    "\n",
    "X_train['horsepower'].fillna(X_train['cylinders'].map(cyl_hp), inplace=True)\n",
    "X_test['horsepower'].fillna(X_test['cylinders'].map(cyl_hp), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.322146425041943\n"
     ]
    }
   ],
   "source": [
    "# check classification accuracy of KNN with K=5\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "print(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What if we created a bunch of train/test splits, calculated the testing accuracy for each, and averaged the results together?\n",
    "\n",
    "**Answer:** That's the essense of cross-validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for K-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the dataset into K **equal** partitions (or \"folds\").\n",
    "2. Use fold 1 as the **testing set** and the union of the other folds as the **training set**.\n",
    "3. Calculate **testing accuracy**.\n",
    "4. Repeat steps 2 and 3 K times, using a **different fold** as the testing set each time.\n",
    "5. Use the **average testing accuracy** as the estimate of out-of-sample accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram of **5-fold cross-validation:**\n",
    "\n",
    "![5-fold cross-validation](images/07_cross_validation_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                   Training set observations                   Testing set observations\n",
      "    1     [ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]        [0 1 2 3 4]       \n",
      "    2     [ 0  1  2  3  4 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]        [5 6 7 8 9]       \n",
      "    3     [ 0  1  2  3  4  5  6  7  8  9 15 16 17 18 19 20 21 22 23 24]     [10 11 12 13 14]     \n",
      "    4     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 21 22 23 24]     [15 16 17 18 19]     \n",
      "    5     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]     [20 21 22 23 24]     \n"
     ]
    }
   ],
   "source": [
    "# simulate splitting a dataset of 25 observations into 5 folds\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=False).split(range(25))\n",
    "\n",
    "# print the contents of each training and testing set\n",
    "print('{} {:^61} {}'.format('Iteration', 'Training set observations', 'Testing set observations'))\n",
    "for iteration, data in enumerate(kf, start=1):\n",
    "    print('{:^9} {} {:^25}'.format(iteration, data[0], str(data[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset contains **25 observations** (numbered 0 through 24)\n",
    "- 5-fold cross-validation, thus it runs for **5 iterations**\n",
    "- For each iteration, every observation is either in the training set or the testing set, **but not both**\n",
    "- Every observation is in the testing set **exactly once**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing cross-validation to train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of **cross-validation:**\n",
    "\n",
    "- More accurate estimate of out-of-sample accuracy\n",
    "- More \"efficient\" use of data (every observation is used for both training and testing)\n",
    "\n",
    "Advantages of **train/test split:**\n",
    "\n",
    "- Runs K times faster than K-fold cross-validation\n",
    "- Simpler to examine the detailed results of the testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. K can be any number, but **K=10** is generally recommended\n",
    "2. For classification problems, **stratified sampling** is recommended for creating the folds\n",
    "    - Each response class should be represented with equal proportions in each of the K folds\n",
    "    - scikit-learn's `cross_val_score` function does this by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation example: parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Select the best tuning parameters (aka \"hyperparameters\") for KNN on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 99.2, 4: 78.3, 5: 82.3, 6: 101.5, 8: 158.3}\n"
     ]
    }
   ],
   "source": [
    "#use those means to impute any missing values\n",
    "cyl_hp = X.groupby('cylinders')['horsepower'].mean().round(1).to_dict()\n",
    "print(cyl_hp)\n",
    "\n",
    "X['horsepower'].fillna(X['cylinders'].map(cyl_hp), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.93742982 10.7329855  12.30951955  8.35275677  5.61140501  6.14088529\n",
      " 18.82015866 11.6929166  37.11300007 16.71048419]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
    "ridge = Ridge(alpha= 0.1)\n",
    "scores = cross_val_score(ridge, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "print(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.641270203161534\n"
     ]
    }
   ],
   "source": [
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "print(-scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.642243329823888, 13.64215414666469, 13.641956479206561, 13.641759521570862, 13.641270203161534]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "alphas = [0.01, 0.1, 0.3, 0.5, 1]\n",
    "a_scores = []\n",
    "for a in alphas:\n",
    "    ridge = Ridge(alpha=a)\n",
    "    scores = cross_val_score(ridge, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "    a_scores.append(-scores.mean())\n",
    "print(a_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements to cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeated cross-validation**\n",
    "\n",
    "- Repeat cross-validation multiple times (with **different random splits** of the data) and average the results\n",
    "- More reliable estimate of out-of-sample performance by **reducing the variance** associated with a single trial of cross-validation\n",
    "\n",
    "**Creating a hold-out set**\n",
    "\n",
    "- \"Hold out\" a portion of the data **before** beginning the model building process\n",
    "- Locate the best model using cross-validation on the remaining data, and test it **using the hold-out set**\n",
    "- More reliable estimate of out-of-sample performance since hold-out set is **truly out-of-sample**\n",
    "\n",
    "**Feature engineering and selection within cross-validation iterations**\n",
    "\n",
    "- Normally, feature engineering and selection occurs **before** cross-validation\n",
    "- Instead, perform all feature engineering and selection **within each cross-validation iteration**\n",
    "- More reliable estimate of out-of-sample performance since it **better mimics** the application of the model to out-of-sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- scikit-learn documentation: [Cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html), [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- scikit-learn issue on GitHub: [MSE is negative when returned by cross_val_score](https://github.com/scikit-learn/scikit-learn/issues/2439)\n",
    "- Section 5.1 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) (11 pages) and related videos: [K-fold and leave-one-out cross-validation](https://www.youtube.com/watch?v=nZAM5OXrktY&list=PL5-da3qGB5IA6E6ZNXu7dp89_uv8yocmf) (14 minutes), [Cross-validation the right and wrong ways](https://www.youtube.com/watch?v=S06JpVoNaA0&list=PL5-da3qGB5IA6E6ZNXu7dp89_uv8yocmf) (10 minutes)\n",
    "- Scott Fortmann-Roe: [Accurately Measuring Model Prediction Error](http://scott.fortmann-roe.com/docs/MeasuringError.html)\n",
    "- Machine Learning Mastery: [An Introduction to Feature Selection](http://machinelearningmastery.com/an-introduction-to-feature-selection/)\n",
    "- Harvard CS109: [Cross-Validation: The Right and Wrong Way](https://github.com/cs109/content/blob/master/lec_10_cross_val.ipynb)\n",
    "- Journal of Cheminformatics: [Cross-validation pitfalls when selecting and assessing regression and classification models](http://www.jcheminf.com/content/pdf/1758-2946-6-10.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiently searching for optimal tuning parameters ([video #8](https://www.youtube.com/watch?v=Gol_qOgRqfA&list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A&index=8))\n",
    "\n",
    "Created by [Data School](http://www.dataschool.io/). Watch all 9 videos on [YouTube](https://www.youtube.com/playlist?list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A). Download the notebooks from [GitHub](https://github.com/justmarkham/scikit-learn-videos).\n",
    "\n",
    "**Note:** This notebook uses Python 3.6 and scikit-learn 0.19.1. The original notebook (shown in the video) used Python 2.7 and scikit-learn 0.16, and can be downloaded from the [archive branch](https://github.com/justmarkham/scikit-learn-videos/tree/archive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- How can K-fold cross-validation be used to search for an **optimal tuning parameter**?\n",
    "- How can this process be made **more efficient**?\n",
    "- How do you search for **multiple tuning parameters** at once?\n",
    "- What do you do with those tuning parameters before making **real predictions**?\n",
    "- How can the **computational expense** of this process be reduced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## More efficient parameter tuning using `GridSearchCV`\n",
    "\n",
    "Allows you to define a **grid of parameters** that will be **searched** using K-fold cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define the parameter values that should be searched\n",
    "alpha_range = [0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "print(alpha_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(alpha=alpha_range)\n",
    "print(param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# instantiate the grid\n",
    "grid = GridSearchCV(ridge, param_grid, cv=10, scoring='neg_mean_squared_error', return_train_score=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- You can set **`n_jobs = -1`** to run computations in parallel (if supported by your computer and OS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-13.575561</td>\n",
       "      <td>8.728057</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.575522</td>\n",
       "      <td>8.728024</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.575473</td>\n",
       "      <td>8.727984</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.575081</td>\n",
       "      <td>8.727666</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-13.574595</td>\n",
       "      <td>8.727277</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-13.570855</td>\n",
       "      <td>8.724513</td>\n",
       "      <td>{'alpha': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-13.566514</td>\n",
       "      <td>8.721849</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score           params\n",
       "0       -13.575561        8.728057  {'alpha': 0.01}\n",
       "1       -13.575522        8.728024  {'alpha': 0.05}\n",
       "2       -13.575473        8.727984   {'alpha': 0.1}\n",
       "3       -13.575081        8.727666   {'alpha': 0.5}\n",
       "4       -13.574595        8.727277     {'alpha': 1}\n",
       "5       -13.570855        8.724513     {'alpha': 5}\n",
       "6       -13.566514        8.721849    {'alpha': 10}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the results as a pandas DataFrame\n",
    "import pandas as pd\n",
    "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n",
      "-13.575561350329162\n"
     ]
    }
   ],
   "source": [
    "# examine the first result\n",
    "print(grid.cv_results_['params'][0])\n",
    "print(grid.cv_results_['mean_test_score'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-13.57556135 -13.57552198 -13.5754728  -13.57508095 -13.57459501\n",
      " -13.5708549  -13.56651449]\n"
     ]
    }
   ],
   "source": [
    "# print the array of mean scores only\n",
    "grid_mean_scores = grid.cv_results_['mean_test_score']\n",
    "print(grid_mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross-Validated MSE')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "plt.plot(alpha_range, grid_mean_scores)\n",
    "plt.xlabel('Value of Alpha for Ridge')\n",
    "plt.ylabel('Cross-Validated MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.566514487899534\n",
      "{'alpha': 10}\n",
      "Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Searching multiple parameters simultaneously\n",
    "\n",
    "- **Example:** tuning `max_depth` and `min_samples_leaf` for a `DecisionTreeClassifier`\n",
    "- Could tune parameters **independently**: change `max_depth` while leaving `min_samples_leaf` at its default value, and vice versa\n",
    "- But, best performance might be achieved when **neither parameter** is at its default value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter values that should be searched\n",
    "penalty = ['l1', 'l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'norm': ['l1', 'l2']}\n"
     ]
    }
   ],
   "source": [
    "# create a parameter grid: map the parameter names to the values that should be searched\n",
    "param_grid = dict(alpha=alpha_range, norm=penalty)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing computational expense using `RandomizedSearchCV`\n",
    "\n",
    "- Searching many different parameters at once may be computationally infeasible\n",
    "- `RandomizedSearchCV` searches a subset of the parameters, and you control the computational \"budget\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "param_dist = dict(n_neighbors=k_range, weights=weight_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Important:** Specify a continuous distribution (rather than a list of values) for any continous parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_iter controls the number of searches\n",
    "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5, return_train_score=False)\n",
    "rand.fit(X, y)\n",
    "pd.DataFrame(rand.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the best model\n",
    "print(rand.best_score_)\n",
    "print(rand.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run RandomizedSearchCV 20 times (with n_iter=10) and record the best score\n",
    "best_scores = []\n",
    "for _ in range(20):\n",
    "    rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, return_train_score=False)\n",
    "    rand.fit(X, y)\n",
    "    best_scores.append(round(rand.best_score_, 3))\n",
    "print(best_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- scikit-learn documentation: [Grid search](http://scikit-learn.org/stable/modules/grid_search.html), [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "- Timed example: [Comparing randomized search and grid search](http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html)\n",
    "- scikit-learn workshop by Andreas Mueller: [Video segment on randomized search](https://youtu.be/0wUF_Ov8b0A?t=17m38s) (3 minutes), [related notebook](https://github.com/amueller/pydata-nyc-advanced-sklearn/blob/master/Chapter%203%20-%20Randomized%20Hyper%20Parameter%20Search.ipynb)\n",
    "- Paper by Yoshua Bengio: [Random Search for Hyper-Parameter Optimization](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
